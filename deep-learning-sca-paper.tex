%% bare_jrnl_seminar.tex
%%
%% This is a slightly modified version of the original IEEEtran example bare_jrnl.tex 
%% to meet the needs for the "advanced seminar for security in information technology"
%% at the institute for security in information technology, TUM. 
%% This template is also applicable for writing German texts.
%% 
%% April 2011, Hermann Seuschek
%%

\documentclass[journal]{IEEEtran}
%\documentclass[10pt,        % Don't change the font size!
%               a4paper,     % Don't change the paper size!
%               journal,     % Journal paper format
%               draft       % Enable this parameter to get a draft version.
%               ]{IEEEtran}
\makeatletter


\def\markboth#1#2{\def\leftmark{\@IEEEcompsoconly{\sffamily}\MakeUppercase{\protect#1}}%
\def\rightmark{\@IEEEcompsoconly{\sffamily}\MakeUppercase{\protect#2}}}
\makeatother

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off.

% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi

% *** MATH PACKAGES ***
%
\usepackage[cmex10]{amsmath}
\interdisplaylinepenalty=2500

% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/

% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/

%\usepackage{mdwmath}
%\usepackage{mdwtab}
% Also highly recommended is Mark Wooding's extremely powerful MDW tools,
% especially mdwmath.sty and mdwtab.sty which are used to format equations
% and tables, respectively. The MDWtools set is already installed on most
% LaTeX systems. The lastest version and documentation is available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/mdwtools/

%\usepackage{eqparbox}
% Also of notable interest is Scott Pakin's eqparbox package for creating
% (automatically sized) equal width boxes - aka "natural width parboxes".
% Available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/eqparbox/

% *** SUBFIGURE PACKAGES ***
%\usepackage[tight,footnotesize]{subfigure}
% subfigure.sty was written by Steven Douglas Cochran. This package makes it
% easy to put subfigures in your figures. e.g., "Figure 1a and 1b". For IEEE
% work, it is a good idea to load it with the tight package option to reduce
% the amount of white space around the subfigures. subfigure.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at:
% http://www.ctan.org/tex-archive/obsolete/macros/latex/contrib/subfigure/
% subfigure.sty has been superceeded by subfig.sty.

%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}
% subfig.sty, also written by Steven Douglas Cochran, is the modern
% replacement for subfigure.sty. However, subfig.sty requires and
% automatically loads Axel Sommerfeldt's caption.sty which will override
% IEEEtran.cls handling of captions and this will result in nonIEEE style
% figure/table captions. To prevent this problem, be sure and preload
% caption.sty with its "caption=false" package option. This is will preserve
% IEEEtran.cls handing of captions. Version 1.3 (2005/06/28) and later 
% (recommended due to many improvements over 1.2) of subfig.sty supports
% the caption=false option directly:
%\usepackage[caption=false,font=footnotesize]{subfig}
%
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/
% The latest version and documentation of caption.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/caption/

% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/

%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Documentation is contained in the stfloats.sty comments as well as in the
% presfull.pdf file. Do not use the stfloats baselinefloat ability as IEEE
% does not allow \baselineskip to stretch. Authors submitting work to the
% IEEE should note that IEEE rarely uses double column equations and
% that authors should try to avoid such use. Do not be tempted to use the
% cuted.sty or midfloat.sty packages (also by Sigitas Tolusis) as IEEE does
% not format its papers in such ways.

%\ifCLASSOPTIONcaptionsoff
%  \usepackage[nomarkers]{endfloat}
% \let\MYoriglatexcaption\caption
% \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
%\fi
% endfloat.sty was written by James Darrell McCauley and Jeff Goldberg.
% This package may be useful when used in conjunction with IEEEtran.cls'
% captionsoff option. Some IEEE journals/societies require that submissions
% have lists of figures/tables at the end of the paper and that
% figures/tables without any captions are placed on a page by themselves at
% the end of the document. If needed, the draftcls IEEEtran class option or
% \CLASSINPUTbaselinestretch interface can be used to increase the line
% spacing as well. Be sure and use the nomarkers option of endfloat to
% prevent endfloat from "marking" where the figures would have been placed
% in the text. The two hack lines of code above are a slight modification of
% that suggested by in the endfloat docs (section 8.3.1) to ensure that
% the full captions always appear in the list of figures/tables - even if
% the user used the short optional argument of \caption[]{}.
% IEEE papers do not typically make use of \caption[]'s optional argument,
% so this should not be an issue. A similar trick can be used to disable
% captions of packages such as subfig.sty that lack options to turn off
% the subcaptions:
% For subfig.sty:
% \let\MYorigsubfloat\subfloat
% \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% For subfigure.sty:
% \let\MYorigsubfigure\subfigure
% \renewcommand{\subfigure}[2][\relax]{\MYorigsubfigure[]{#2}}
% However, the above trick will not work if both optional arguments of
% the \subfloat/subfig command are used. Furthermore, there needs to be a
% description of each subfigure *somewhere* and endfloat does not add
% subfigure captions to its list of figures. Thus, the best approach is to
% avoid the use of subfigure captions (many IEEE journals avoid them anyway)
% and instead reference/explain all the subfigures within the main caption.
% The latest version of endfloat.sty and its documentation can obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/endfloat/
%
% The IEEEtran \ifCLASSOPTIONcaptionsoff conditional can also be used
% later in the document, say, to conditionally put the References on a 
% page by themselves.

% *** PDF, URL AND HYPERLINK PACKAGES ***
\usepackage{url}
% \url{my_url_here}.

% Referencing paragraphs/pictures using \autoref after assigning \label
\usepackage{hyperref}
\hypersetup{colorlinks=false}


% properly print units, enable compact product between units
\usepackage[inter-unit-product =\cdot]{siunitx}
% load units \bit, \byte usw
\sisetup{detect-weight=true, binary-units=true}

%\usepackage[backend=biber,sortlocale = auto, isbn = false, doi=false, citestyle = numeric-comp,firstinits=true]{biblatex}
%\addbibresource{literature.bib}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}

\title{Using Deep Learning Techniques to augment Side Channel Analysis}
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%

\author{Nimar~Blume}% <-this % stops a space
%\thanks{Fabrizio Desantis, Chair of Security in Information Technology of the Technical University of Munich}% <-this % stops a space

% note the % following the last \IEEEmembership and also \thanks - 
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
% 
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.

% The paper headers
%\markboth{Hauptseminar Sicherheit in der Informationstechnik, Sommersemester 2011}%
\markboth{Advanced Seminar for Security in Information Technology, Summer Term 2017}%
{Nimar Blume: Using Deep Learning Techniques to augment Side Channel Analysis}

%\markboth{Journal of \LaTeX\ Class Files,~Vol.~6, No.~1, January~2007}%
%{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Journals}
% The only time the second header will appear is for the odd numbered pages
% after the title page when using the twoside option.
% 
% *** Note that you probably will NOT want to include the author's ***
% *** name in the headers of peer review papers.                   ***
% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if
% you desire.

% If you want to put a publisher's ID mark on the page you can do it like
% this:
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2007 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}

% make the title area
\maketitle

\begin{abstract}
%\boldmath
At the moment, cryptography is everywhere, allowing endpoints to transmit data securely over an insecure network. A multitude of encryption algorithms are available but even those which have no proven weakness theoretically can be attacked by attacking the algorithm's implementation. Therefore, leaking side channel data such as a chip's power consumption can be used to infer parts of or the entire secret key. Currently, the Template Attack (TA) is the most powerful side channel attack (SCA), requiring the least amount of side channel data in the attack phase. However, recently Machine Learning (ML) based TAs were shown to supersede traditional TAs in efficiency. Since Deep Learning (DL) techniques have beaten ML techniques in for example object recognition in images, this paper examines viability and performance of DL techniques in SCAs. In the end, especially Convolutional Neural Networks have proven to be more effective than traditional SCA techniques such as TAs.
\end{abstract}
% IEEEtran.cls defaults to using nonbold math in the Abstract.
% This preserves the distinction between vectors and scalars. However,
% if the journal you are submitting to favors bold math in the abstract,
% then you can use LaTeX's standard command \boldmath at the very start
% of the abstract to achieve this. Many IEEE journals frown on math
% in the abstract anyway.

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
deep learning, neural network, side channel analysis, side channel attack, encryption, AES
\end{IEEEkeywords}

% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
% \IEEEpeerreviewmaketitle

\section{Introduction}
Data encryption is commonly employed to restrict data access to selected people or endpoints. Proper encryption provides privacy, integrity and authenticity of data exchanged between two or more parties over an insecure connection. An encryption key or a pair of keys is generated with which the chosen data is encrypted, so that the data can only be read or modified by an endpoint who possesses the appropriate secret key. For symmetric encryption, where the same secret key is used to encrypt and decrypt data, the key has to be shared over a secure connection beforehand, whereas asymmetric encryption uses key pairs, one of which is used to encrypt and one is used to decrypt data. Therefore, asymmetric encryption enables two parties to exchange data securely over an insecure connection by publishing the key used for encryption and keeping the key used for decryption private. This paper will only consider attacking symmetric encryption, although techniques discussed could also partly be applied to asymmetric encryption algorithms. Encryption algorithms have been attacked in multiple ways, and attacking the algorithms implementation has proven to be effective against cryptographically sound algorithms. In the past, machine learning (ML) has been used to attack implementations as part of the profiling stage in Template attacks (\autoref{subsec:template}). As deep learning (DL) recently has made a comeback and consistently outperforms ML techniques in areas such as image recognition (XXXX INSERT SOURCE), applying DL techniques to breaking cryptographic algorithms is attractive to investigate. In the end, consistently with the improvement seen in image recognition, DL techniques improve ML based attacks and require fewer traces to select the correct secret key in a side channel attack on AES (\autopageref{sc:aes}).  

\subsection{The Advanced Encryption Standard}
\label{sc:aes}
While there are many encryption algorithms available, this paper focuses on the most popular symmetric block cipher: the Advanced Encryption Standard (henceforth AES) with a \SI{128}{\bit} key. The AES algorithm encrypts data in blocks of \SI{128}{\bit} or \SI{16}{\byte}. Should a block be smaller than \SI{16}{\byte}, padding will be appended until the block size reaches \SI{16}{\byte}. Furthermore, AES expands a single \SI{128}{\bit} key to 11 round keys which are then used in the subsequent 11 rounds to encrypt the given data. It is important to note, that a compromise of any of the 11 round keys enables an attacker to reconstruct the initial \SI{128}{\bit} key and thus decrypt the whole encrypted data set. 

\subsection{Side Channel Analysis}
Side Channel Analysis (henceforth SCA) refers to a technique used to break encryption schemes by using data indirectly generated by the implementation of the cryptographic algorithm, instead of attacking the algorithm itself. Even a theoretically perfectly safe cryptographic algorithm can be subject to SCA and be broken by it. SCA uses side channels such as the power consumption of a microprocessor, electro magnetic emissions or even emitted sound to reconstruct the entire or parts of the secret key used to encrypt the data. It can be possible to infer the secret key form side channel data due to data dependant program flows. Specifically, the code contains conditional statements acting on the secret key data. For example a certain loop will only execute if the currently processed key bit is zero, therefore the power consumption of the microprocessor will measurably increase. Furthermore, power modelling is used to predict a microprocessor's power consumption based on the secret key data. Power models such as Hamming Weight (a "1" consumes more energy to be processed than a "0") or Hamming Distance (bitwise comparison resulting in the number of different bits) are popular choices. Therefore, to protect against SCA it is vital to pay attention not only on the theoretical safety of an encryption algorithm but also on its implementation.

\section{State of the Art}
State of the art of crypto attacks

\subsection{The state of Side Channel Analysis}
Side channel attacks were first developed in 1996 by Paul Kocher \cite{first-sca:kocher} in the form of timing attacks. Timing attacks can exploit an implementation's execution flow dependence on secret key data. Later, SCAs have been extended to infer secret key data by analysing a processor's power consumption and its dependence on secret key data. 

\subsubsection{Simple Power Analysis}
Simple Power Analysis (henceforth SPA) is a SCA based on the power consumption of the target device. The target device (e.g. a smart card) performs multiple encryption or decryption operations during which the attacker measures the device's power consumption. The attacker does not know the plaintext, which makes it a ciphertext only attack (COA). Then, the attacker calculates a hypothetical power consumption for each possible key combination using for example the Hamming Weight model. Finally, he correlates the hypothetical power consumption to the measured power traces and then ranks the hypothetical keys accordingly. The correct key should now be among the top ranked hypothetical keys. However, SPA is very reliant on clean power traces. Modern computers perform many operations in parallel and thus generate a lot of noise, which is why SPA is best used on simple devices like smart cards. 

\subsubsection{Differential Power Analysis}
Differential Power Analysis (henceforth DPA) is similar to SPA because it also tries to extract the secret key from a device by using power traces taken during a operation. However, in contrast to the SPA, multiple power traces are taken during different device states. Power traces of the target device are also taken while the device is idle to determine the background noise. The noise level is then subtracted from the power traces taken during the cryptographic operation, resulting in a more distinct signal. Still, concurrent operations running parallel to the cryptographic operations worsen the quality of the power traces, but that can be compensated by taking a large number of traces and averaging over them. Thus, DPA can also be used on more complex devices than smart cards.

\subsubsection{High-order Differential Power Analysis}
High-order Differential Power Analysis (henceforth HO-DPA) is similar to DPA but additionally, further power traces are taken at multiple steps of the cryptographic operation. HO-DPA allows to attack implementations using masking to hide cryptographic operations, by taking power traces at the mask generation thereby demasking the final encryption operation. However, due to taking many different traces and correlating them with one another, HO-DPAs are highly complex and not used when a DPA or a SPA could also be used to mount a viable attack on an implementation.

\subsubsection{Template Attacks}
\label{subsec:template}
A Template Attack is a very powerful, targeted attack on an implementation of a cryptographic algorithm. The premise is, that the attacker has restricted access to the target machine, but ubiquitous access to similar machines containing a varying secret key. The attacker can now execute many encryption operations while varying the secret key and recording power traces. The goal is to acquire a large labelled data set, which maps power consumption to key bits on the specific type of machine. Afterwards, the attacker trains a machine learning model using the previously acquired labelled dataset. For example, a Support Vector Machine (SVM) is trained to rank key hypotheses given power traces as data input. Finally, the attacker obtains a small number of power traces from the target machine containing the secret key during an encryption or decryption operation and feeds the power trace along with the key hypotheses into the SVM for analysis. The SVM will now rank the potentially correct key the highest, resulting in a successful attack.

$ f_z(L|Z=z) \simeq \dfrac{1}{(2\pi)\^{d}det(\Sigma_z)}exp(-\frac{1}{2}(L-\mu_z)\^{T}\Sigma_z(L-\mu_z)) $

% needed in second column of first page if using \IEEEpubid
%\IEEEpubidadjcol

\section{Theory}
\subsection{Using Deep Learning over Machine Learning}
DL techniques differentiate themselves from ML techniques in that ML relies on features selected by the attacker manually, for example power traces are correlated with hypothetical key values and subsequently points of interest (POIs) chosen based on the correlation. Using DL techniques, the input consists of raw data and the NN chooses the POIs itself. In fact, applying a principal component analysis before feeding the data into the NN for dimensionality reduction reduces the NN's effectiveness as shown in \cite[p.~15]{breaking-crypto-dl:prouff} due to possibly removing vital information to achieve lower dimensional data.

\subsection{Multi layer perceptron}
\label{sc:mlp}
A Multilayer perceptron (MLP) is a Neural Network built out of perceptrons, which are single neuron representations often used in computer science. A perceptron consists of one or multiple inputs which are multiplied by respective weights and then fed into an activation function. The activation function then determines the output of a single perceptron. A popular choice for an activation function is the rectified linear unit (ReLU): $ f(x)=max(0, x) $, because the output is not limited to a value between "1" and "-1" only. A MLP consists of a number of perceptrons ordered into layers, of which each perceptron is connected to every perceptron in the following layer. When training MLPs, the predicted output of a perceptron in the last layer $ \hat{Y}\_i $ is compared to the desired output $ Y_i $ and the error is calculated: $ E_i = (\hat{Y}_i - Y_i)\^{2} $. The gradient descend algorithm is then used to adjust the weights step by step to minimise the error and thus train the NN. 

\subsection{Convolutional Neural Networks}
Convolutional Neural Networks (henceforth CNN) are Neural Networks (NN) which have recently risen in popularity due to their strength in classifying images. They are good at extracting features from input data represented in a 2nd order tensor invariant from the features scale, rotation or vicinity. Feature maps are created from the input through stacked convolutional layers until a reasonably small and thus dense feature map is created. The extracted feature maps do not represent features which commonly are extracted manually. 

\subsubsection{Convolutional layer}
The Convolutional layer of a CNN is responsible for extracting features from the inputs. A feature map is extracted from the input data by convoluting a filter tensor with the input tensor. The filter is a 2nd order tensor of a smaller size than the input and usually initialised with small random variables which are adjusted in the training phase. As displayed in XXXX TODO. After one convolution the output size decreases but still represents the same information, thus extracting features, a feature map.  

\subsubsection{Fully connected layer}
\label{sssec:fcl}
A fully connected layer (FCL) is a layer of multiple Multi layer perceptrons (MLP, \autoref{sc:mlp}) of which each is connected to every MLP in the subsequent layer. FCL are commonly used as output layer in a CNN because it is very easy to tune it to the desired number of outputs per calculation cycle.

\subsubsection{Pooling layer}
"Downsampling", Max Pooling
\subsubsection{Normalisation layer}
"Softmax" A normalisation layer is used in a CNN to 

\subsection{Stacked Auto-Encoders}
Stacked Auto-Encoders (AE) consist of an encoder layer followed by multiple FCL (\autoref{sssec:fcl}) and at the end feature a decoder layer. During training the goal of an AE is to reproduce the given input at the output. Its weights are then trained by gradually adding noise to the input data while the network should still output the original, denoised input. The FCLs are generally sized smaller than the number of inputs as to extract a more compact feature set from which the input data can then be recreated. Finally, after training multiple encoding layers, the decoding layer at the end is removed and the trained encoding layers are stacked onto one another to produce a NN. % TODO why? 

\subsection{Recurrent Neural Networks}
Good for for data which has connections to itself in i.e. different points in time.
\subsection{Long and Short Term Memory (RNN)}

\subsection{Using Deep Learning to improve Side Channel Analysis}
Deep Learning assists Side Channel Analysis in that it provides a new method of profiling, and subsequently a new engine for attacking as well. DL techniques can be used in Template Attacks (\autoref{subsec:template}) in the profiling phase instead of the Gaussian assumption of the leakage. A NN is then trained instead using the available labelled data set of power traces with corresponding key data. First, power traces are recorded during cryptographic operations which use the key data. In this case, \SI{1000}{piece} traces per key byte were recorded. 

Afterwards, the Side Channel Attack itself is performed in the same manner as a Template Attack \autoref{subsec:template}. The trained NN can be of different types as discussed above and 

The output of a NN in assisting SCA is a vector assigning a probability to each key hypothesis. 



Regular research papers need at least two additional sections here. One section
for contributions and methods and one section for the results. For seminar
papers these sections can be omitted. 

\section{Experimental results}
Deep Learning (DL) techniques can improve SCA significantly if employed correctly. It is however essential to pick the appropriate DL technique for the working data set to get the best or even a better result than without using DL techniques.
Show the results from the paper which covered the same topic.

% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation Results}
%\label{fig_sim}
%\end{figure}

% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command, the
% \label for the overall figure must come after \caption.
% \hfil must be used as a separator to get equal spacing.
% The subfigure.sty package works much the same way, except \subfigure is
% used instead of \subfloat.
%
%\begin{figure*}[!t]
%\centerline{\subfloat[Case I]\includegraphics[width=2.5in]{subfigcase1}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{subfigcase2}%
%\label{fig_second_case}}}
%\caption{Simulation results}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.

% An example of a floating table. Note that, for IEEE style tables, the 
% \caption command should come BEFORE the table. Table text will default to
% \footnotesize as IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}

% Note that IEEE does not put floats in the very first column - or typically
% anywhere on the first page for that matter. Also, in-text middle ("here")
% positioning is not used. Most IEEE journals use top floats exclusively.
% Note that, LaTeX2e, unlike IEEE journals, places footnotes above bottom
% floats. This can be corrected via the \fnbelowfloat command of the
% stfloats package.

\section{Conclusion}
Put the conclusions of the work here. The conclusion is like the abstract with
an additional discussion of open points.

% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%

% \appendices
% \section{Proof of the First Zonklar Equation}
% Appendix one text goes here.

% you can choose not to have a title for an appendix
% if you want by leaving the argument blank
% \section{}
% Appendix two text goes here.

% use section* for acknowledgement
%\section*{Acknowledgment}

%The authors would like to thank...

% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi


% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,literature}

\end{document}
